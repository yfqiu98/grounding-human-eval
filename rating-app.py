import os
import json
import random
import streamlit as st
import pandas as pd
from datetime import datetime

import base64
import requests

def upload_to_github(file_path, commit_message):
    token = st.secrets["github"]["token"]
    repo = st.secrets["github"]["repo"]
    api_url = f"https://api.github.com/repos/{repo}/contents/{file_path}"

    with open(file_path, "rb") as f:
        content = base64.b64encode(f.read()).decode()

    headers = {
        "Authorization": f"token {token}",
        "Accept": "application/vnd.github.v3+json"
    }

    data = {
        "message": commit_message,
        "content": content
    }

    # check if file already exists
    r = requests.get(api_url, headers=headers)
    if r.status_code == 200:
        sha = r.json()["sha"]
        data["sha"] = sha

    r = requests.put(api_url, headers=headers, json=data)
    if r.status_code in [200, 201]:
        st.success("‚úÖ File successfully uploaded to GitHub.")
    else:
        st.error(f"‚ùå GitHub upload failed: {r.status_code} {r.text}")

MODELS = ["got", "chameleon-sft", "chameleon-unsup-sft", "SmartEdit-7B"]
OUTPUT_DIR = "outputs"
# ========== CONFIG ==========
if "EVAL_INDICES" not in st.session_state:

    # EVAL_INDICES = [0, 4, 50, 51, 52, 100, 101, 102, 200, 380]

    mb_remove_ids = [5, 7, 9, 12, 13, 15, 19, 21, 23, 28, 29, 31, 34, 37]
    ag_remove_ids = [53, 61, 64, 68, 69, 72, 77, 81, 84, 89, 92, 93, 95, 97, 98, 99]
    something_remove_ids = [119, 124, 126, 135, 136, 145, 146, 147, 148, 149]
    kubric_remove_ids = [355, 360, 365, 370, 373, 375, 378, 385, 392]

    mb_ids = [i for i in range(0,50) if i not in mb_remove_ids] 
    ag_ids = [i for i in range(50,100) if i not in ag_remove_ids]
    something_ids = [i for i in range(100,150) if i not in something_remove_ids]
    whatsup_ids = [i for i in range(200,250)] 
    kubric_ids = [i for i in range(350,400) if i not in kubric_remove_ids]

    import random

    selected_mb_ids = random.sample(mb_ids, k=5)
    selected_ag_ids = random.sample(ag_ids, k=5)
    selected_something_ids = random.sample(something_ids, k=5)
    selected_whatsup_ids = random.sample(whatsup_ids, k=5)
    selected_kubric_ids = random.sample(kubric_ids, k=5)

    # EVAL_INDICES = selected_mb_ids+selected_ag_ids+selected_something_ids+selected_whatsup_ids+selected_kubric_ids
    st.session_state.EVAL_INDICES = selected_mb_ids + selected_ag_ids + selected_something_ids + selected_whatsup_ids + selected_kubric_ids

EVAL_INDICES = st.session_state.EVAL_INDICES
print(EVAL_INDICES)

TEST_JSON = "test.json"
OUTPUT_PATH = "results"

# ========== LOAD DATA ==========
with open(TEST_JSON, "r") as f:
    test_data = json.load(f)

# ========== SESSION STATE INIT ==========
if "user_id" not in st.session_state:
    st.session_state.user_id = ""
if "annotations" not in st.session_state:
    st.session_state.annotations = []
if "index" not in st.session_state:
    st.session_state.index = 0
if "shuffle_orders" not in st.session_state:
    st.session_state.shuffle_orders = {}

# ========== UI: USER ID ==========
st.title("Anonymous Human Evaluation for Image Editing Models")
st.session_state.user_id = st.text_input("Enter your user ID:", value=st.session_state.user_id)

if not st.session_state.user_id:
    st.warning("Please enter a user ID to begin.")
    st.stop()
    
# ========== INTRODUCTION PAGE ==========
if "intro_shown" not in st.session_state:
    st.session_state.intro_shown = False

if not st.session_state.intro_shown:
    st.header("üìù Evaluation Instructions")

    st.markdown("""
    Welcome, and thank you for participating in this human evaluation study!

    In this task, you will see **image editing results** generated by different anonymous models. If the candidates are too small, you can click the top-right buttom to magnify edited images when you put your mouse on the candidate images.
    
    For each example, your job is to rate the systems from 0-3 according to the satisfication of three criterion:

    ---

    ### üé≠ Criterion 1: Realism
    - **Good**: The generated image looks like a real photo with natural textures and lighting, mostly follows the scene in the input image.
    - **Bad**: Artifacts, distortions, or unnatural results.
    
    ### üîß Criterion 2: Instruction Followed
    - **Good**: The edit reflects the instruction clearly (e.g., "add a tree" results in a tree in the scene).
    - **Bad**: The edit misses the point or wrongly changes something irrelevant.

    ### üé® Criterion 3: Over-editing
    - **Good**: The edit is focused and minimal, changing only what was requested.
    - **Bad**: More than what was requested is changed (e.g., adding or altering extra objects).
    ---
    
    ### Evaluation Rules:
    
    - Rate each candidate based on the following 3 criteria, from 0 to 3:

        - **0**: None of the criteria are satisfied  
        - **1**: Only one is satisfied  
        - **2**: Two are satisfied  
        - **3**: All three are satisfied  

    Criteria:
    1. üé≠ **Realism**
    2. üîß **Instruction Followed**
    3. üé® **Minimal Over-Editing**
    
    
    """)
    st.markdown("### Example instruction: make her turn left")
    st.image("sample_images/input.png", use_container_width=True)
    
    col0, col1, col2, col3 = st.columns(4)
    
    with col0:
        st.image("sample_images/positive.png", caption="‚úÖ Follows instruction well, realistic, and not over-edited)", use_container_width=True)
    with col1:
        st.image("sample_images/negative-overedit.png", caption="‚ùå Over-edited\n(Explanation: the woman has turned left correctly, but there is an extra people is added into the scene.", use_container_width=True)
    with col2:
        st.image("sample_images/negative-donotedit.png", caption="‚ùå Instruction Not Followed\n(Explnation: model fails to follow the instruction and perform the editing.)", use_container_width=True)
    with col3:
        st.image("sample_images/negative-unrealistic.png", caption="‚ùå Unrealistic\n(Explnation: distorted scene, and model fails to produce the output according to the input.)", use_container_width=True)

    st.markdown("""
    ---
    When you're ready, click below to start evaluating. You can always return to a previous sample to modify your response.
    """)


    if st.button("Start Evaluation"):
        st.session_state.intro_shown = True
        st.rerun()

    st.stop()

# ========== EVALUATION FLOW ==========
i = st.session_state.index
if i >= len(EVAL_INDICES):
    st.success("You have completed all evaluations. Thank you!")
    df = pd.DataFrame(st.session_state.annotations)
    os.makedirs(OUTPUT_PATH, exist_ok=True)
    filename = f"{OUTPUT_PATH}/annotations_{st.session_state.user_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
    df.to_csv(filename, index=False)

    # Upload to GitHub
    remote_filename = f"results/{os.path.basename(filename)}"
    commit_message = f"Add annotation file: {remote_filename}"
    upload_to_github(remote_filename, commit_message)

    st.write("Your annotations have been saved locally and pushed to GitHub:")
    st.code(remote_filename)
    st.stop()

# ========== DISPLAY SAMPLE ==========
sample_index = EVAL_INDICES[i]
sample = test_data[sample_index]

# Shuffle display order but store it to ensure correct mapping
if sample_index not in st.session_state.shuffle_orders:
    shuffled_models = MODELS.copy()
    random.shuffle(shuffled_models)
    st.session_state.shuffle_orders[sample_index] = shuffled_models
else:
    shuffled_models = st.session_state.shuffle_orders[sample_index]

# ========== DISPLAY ==========
st.markdown(f"#### Image ID: `{sample_index}`")
st.markdown(f"<h3 style='color:#333'>Instruction for Editing: {sample['instruction']}</h3>", unsafe_allow_html=True)

st.markdown("**Input Image**")
st.image(sample['input'], width=300)

st.markdown(f"#### Image ID: `{sample_index}`")

st.markdown("### Please evaluate each candidate image individually")
st.markdown("""
You will see the **input image**, the **instruction**, and **one model's output** at a time.

Rate how well the output satisfies the following three criteria (0‚Äì3 scale):

- üé≠ Realism  
- üîß Instruction Followed  
- üé® Minimal Over-Editing  
""")

rating_scores = {}
image_filename = f"{sample_index}.png"
model_display_info = []

for idx, model in enumerate(shuffled_models):
    tag = f"Model {idx+1}"
    img_path = os.path.join(OUTPUT_DIR, model, image_filename)
    model_display_info.append((tag, model, img_path))
    
for idx, (tag, model, img_path) in enumerate(model_display_info):
    st.markdown("---")
    st.markdown(f"### Candidate {idx+1} ({tag})")

    col_input, col_output = st.columns([1, 1])

    with col_input:
        st.markdown("**Input Image**")
        st.image(sample['input'], use_container_width=True)

    with col_output:
        st.markdown("**Model Output**")
        st.image(img_path, use_container_width=True)

    st.markdown(f"**Instruction:** `{sample['instruction']}`")
    score = st.radio(
        "How well does this output meet the 3 criteria? (üé≠ Realism & üîß Instruction & üé® Over-Editing)",
        [0, 1, 2, 3],
        index=1,
        key=f"score-radio-{sample_index}-{model}"
    )
    rating_scores[model] = score

# ========== SUBMIT ==========
if st.button("Submit Evaluation"):
    for model in MODELS:
        record = {
            "user_id": st.session_state.user_id,
            "sample_index": sample_index,
            "model": model,
            "score": rating_scores[model],
        }
        st.session_state.annotations.append(record)

    st.session_state.index += 1
    st.experimental_set_query_params()
    st.rerun()
    
# ========== RETURN TO PREVIOUS ==========
if st.session_state.index > 0:
    if st.button("‚Üê Return to Previous Sample"):
        prev_index = st.session_state.index - 1
        st.session_state.index = prev_index
        st.session_state.annotations = [
            r for r in st.session_state.annotations if r["sample_index"] != EVAL_INDICES[prev_index]
        ]
        st.experimental_set_query_params()
        st.rerun()